{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform updates on the python modules\n",
    "# !pip install --user -q opencv-python\n",
    "# !pip install --user -q numpy\n",
    "# !pip install --user -q matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.2.0\n",
      "1.18.2\n",
      "3.1.1\n"
     ]
    }
   ],
   "source": [
    "# version check, see if there are newer versions\n",
    "print(cv2.__version__)\n",
    "print(np.__version__)\n",
    "print(mpl.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\gdioni\\\\Desktop\\\\Jupyter Notebook\\\\OpenCV'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make sure the current directory is also where the folder the notebook resides in!\n",
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Processing Events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Set_Tracker(t_type_lst: list, t_type_index : int):\n",
    "  # get the tracker list and get the current index\n",
    "  tracker_name = t_type_lst[t_type_index]\n",
    "  # Tracker creation\n",
    "  tracker = None\n",
    "  if tracker_name == t_type_lst[0]: \n",
    "    # BOOSTING\n",
    "    tracker = cv2.TrackerBoosting_create()\n",
    "  elif tracker_name == t_type_lst[1]:\n",
    "    # MIL\n",
    "    tracker = cv2.TrackerMIL_create()\n",
    "  elif tracker_name == t_type_lst[2]:\n",
    "    # KCF\n",
    "    tracker = cv2.TrackerKCF_create()\n",
    "  elif tracker_name == t_type_lst[3]:\n",
    "    # TLD\n",
    "    tracker = cv2.TrackerTLD_create()\n",
    "  elif tracker_name == t_type_lst[4]:\n",
    "    # MEDIANFLOW\n",
    "    tracker = cv2.TrackerMedianFlow_create()\n",
    "  elif tracker_name == t_type_lst[5]:\n",
    "    # GOTURN\n",
    "    tracker = cv2.TrackerGOTURN_create()\n",
    "  elif tracker_name == t_type_lst[6]:\n",
    "    # CSRT\n",
    "    tracker = cv2.TrackerCSRT_create()\n",
    "  elif tracker_name == t_type_lst[7]:\n",
    "    tracker = cv2.TrackerMOSSE_create()\n",
    "  else:\n",
    "    print('Something went wrong initializing the tracker')\n",
    "  return tracker\n",
    "def Track_Object(dframe : np.array, tracker : 'tracker')->np.array:\n",
    "  global ball_tracker_bbox, thickness, ball_bbox_upscale, downscale_size\n",
    "\n",
    "  tracked, ball_tracker_bbox = tracker.update(dframe)\n",
    "  FLAG_TRACKER_OK = tracked\n",
    "  if not tracked:\n",
    "    ball_tracker_bbox =  (-1,-1,-1,-1)\n",
    "  return dframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detection using YOLOv3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detection Helper Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the names of the output layers\n",
    "def getOutputsNames(net):\n",
    "    # Get the names of all the layers in the network\n",
    "    layersNames = net.getLayerNames()\n",
    "    # Get the names of the output layers, i.e. the layers with unconnected outputs\n",
    "    return [layersNames[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n",
    "\n",
    "# Draw the predicted bounding box\n",
    "def drawPred(frame, classId, conf, left, top, width, height):\n",
    "    global bbox_detector_color, thickness\n",
    "\n",
    "    # Draw a bounding box.\n",
    "    cv2.rectangle(frame, (left, top), (left+width, top+height), bbox_detector_color, thickness, cv2.LINE_AA)\n",
    "    label = '%.2f' % conf\n",
    "        \n",
    "    # Get the label for the class name and its confidence\n",
    "    if classes:\n",
    "        assert(classId < len(classes))\n",
    "        label = '%s:%s' % (classes[classId], label)\n",
    "        \n",
    "    #Display the label at the top of the bounding box\n",
    "    # labelSize, baseLine = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)\n",
    "    # top = max(top, labelSize[1])\n",
    "    # cv2.rectangle(frame, (left, top - round(1.5*labelSize[1])), (left + round(1.5*labelSize[0]), top + baseLine), (255, 255, 255), cv2.FILLED)\n",
    "    # cv2.putText(frame, label, (left, top), cv2.FONT_HERSHEY_SIMPLEX, 0.75, (0,0,0), 1)\n",
    "    return\n",
    "\n",
    "# Remove the bounding boxes with low confidence using non-maxima suppression\n",
    "def postprocess(frame, outs):\n",
    "    global ball_detector_bbox, FLAG_DETECT_OK\n",
    "    frameHeight = frame.shape[0]\n",
    "    frameWidth = frame.shape[1]\n",
    "\n",
    "    classIds = []\n",
    "    confidences = []\n",
    "    boxes = []\n",
    "    # Scan through all the bounding boxes output from the network and keep only the\n",
    "    # ones with high confidence scores. Assign the box's class label as the class with the highest score.\n",
    "    classIds = []\n",
    "    confidences = []\n",
    "    boxes = []\n",
    "    for out in outs:\n",
    "        for detection in out:\n",
    "            if detection[4] > objectnessThreshold :\n",
    "                scores = detection[5:]\n",
    "                classId = np.argmax(scores)\n",
    "                confidence = scores[classId]\n",
    "                if confidence > confThreshold and classId == 32:\n",
    "                    # 'classId == 32' are sports ball objects\n",
    "                    # only interested in detected sports ball objects\n",
    "                    center_x = int(detection[0] * frameWidth)\n",
    "                    center_y = int(detection[1] * frameHeight)\n",
    "                    width = int(detection[2] * frameWidth)\n",
    "                    height = int(detection[3] * frameHeight)\n",
    "                    left = int(center_x - width / 2)\n",
    "                    top = int(center_y - height / 2)\n",
    "                    classIds.append(classId)\n",
    "                    confidences.append(float(confidence))\n",
    "                    boxes.append([left, top, width, height])\n",
    "\n",
    "    # Perform non maximum suppression to eliminate redundant overlapping boxes with\n",
    "    # lower confidences.\n",
    "    indices = cv2.dnn.NMSBoxes(boxes, confidences, confThreshold, nmsThreshold)\n",
    "#     print('number of indices: ' + str(len(indices)))\n",
    "    \n",
    "    if len(indices) <= 0:\n",
    "      ball_boxes_bb = (-1,-1,-1,-1)\n",
    "      FLAG_DETECT_OK = False\n",
    "      return\n",
    "    # bounding boxes for detection\n",
    "    for i in indices:\n",
    "        i = i[0]\n",
    "        box = boxes[i]\n",
    "        left = box[0]\n",
    "        top = box[1]\n",
    "        width = box[2]\n",
    "        height = box[3]\n",
    "        \n",
    "        # get the bounding box\n",
    "        ball_detector_bbox = (left, top, width, height)\n",
    "    FLAG_DETECT_OK = True\n",
    "    return\n",
    "    \n",
    "def Detect_Object(frame: np.array):\n",
    "  # Create a 4D blob from a frame.\n",
    "  blob = cv2.dnn.blobFromImage(frame, 1/255, (inpWidth, inpHeight), [0,0,0], 1, crop=False)\n",
    "\n",
    "  # Sets the input to the network\n",
    "  net.setInput(blob)\n",
    "\n",
    "  # Runs the forward pass to get output of the output layers\n",
    "  outs = net.forward(getOutputsNames(net))\n",
    "  #outs = net.forward()\n",
    "\n",
    "  # Remove the bounding boxes with low confidence\n",
    "  postprocess(frame, outs)\n",
    "  return frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keyboard Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EventKeyR_iniReset():\n",
    "  global ini_frame_copy, ini_frame\n",
    "  ini_frame = np.copy(ini_frame_copy)\n",
    "  ini_flag = False\n",
    "  return\n",
    "def EventKeyEnter_ini():\n",
    "  global ini_flag\n",
    "  ini_flag = True\n",
    "  return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trackbar Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EventTrkChangeTrackerType(*args):\n",
    "  '''\n",
    "  Changes t_type_index to the value from the trackbar \n",
    "  '''\n",
    "  global t_type_index, FLAG_CHANGE_TRACKER\n",
    "  t_type_index = args[0]\n",
    "  FLAG_CHANGE_TRACKER = True\n",
    "  return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HELPER METHOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ValidateTracker(tracker_bb:tuple, detector_bb:tuple, tracker: 'Tracker object', frame) -> tuple:\n",
    "  '''\n",
    "  If the tracker's center point goes beyond the detector's rectangle\n",
    "  set the tracker to the detector's bounding box\n",
    "  '''\n",
    "  global t_type_index, t_type_lst\n",
    "  print('tracker: ' + str(tracker_bb))\n",
    "  print('detector: ' + str(detector_bb))\n",
    "  t0, t1, tw, th = tracker_bb\n",
    "  d0, d1, dw, dh = detector_bb\n",
    "  \n",
    "  if sum([d0, d1, dw, dh]) <= 0:\n",
    "    return tracker, tracker_bb\n",
    "#   t0, t1, tw, th = tracker_bb\n",
    "#   d0, d1, dw, dh = detector_bb\n",
    "\n",
    "  # get tracker center\n",
    "  x, y = t0-(tw//2), t1-(th//2)\n",
    "\n",
    "  # get detector left, top, right, bottom coordinates\n",
    "  x1, y1, x2, y2 = d0, d1, d0+dw, d1+dh\n",
    "  valid = PointInsideRectange(x1,y1,x2,y2, x, y)\n",
    "  row, col, dim = frame.shape\n",
    "  d0, d1, dw, dh = int(max(0, d0)), int(max(0, d1)), int(max(0, dw)), int(max(0, dh))\n",
    "  if not valid and (0 <= d0 and 0 <= dw and d0 + dw <= col and 0 <= d1 and 0 <= dh and d1 + dh <= row):\n",
    "    '''\n",
    "    if the tracker went outside the detector rectangle and detector_bb won't cause initialization issues\n",
    "    '''\n",
    "    print(d0 > 0, d1 > 0, d0+dw > 0, d1+dh > 0)\n",
    "    tracker = Set_Tracker(t_type_lst, t_type_index)\n",
    "    _ = tracker.init(frame_downscale, (d0, d1, dw, dh))\n",
    "  elif not valid:\n",
    "    '''\n",
    "    if the tracker was invalid but the detector_bb will cause an issue\n",
    "    simply invalidate the current tracker_bb and wait later\n",
    "    '''\n",
    "    tracker_bb = (-1,-1,-1,-1)\n",
    "  return tracker, tracker_bb\n",
    "\n",
    "\n",
    "def PointInsideRectange(x1, y1, x2, y2, x, y) -> bool:\n",
    "  if x > x1 and x < x2 and y > y1 and y < y2:\n",
    "    return True\n",
    "  else:\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert the video path here for ball tracking\n",
    "path_vid = '.\\soccer-ball.mp4'\n",
    "cap = cv2.VideoCapture(path_vid)\n",
    "\n",
    "'''\n",
    "+++ TRACKER configuration\n",
    "'''\n",
    "win_name = 'Tracker'\n",
    "ini_win_name = 'Select object bounding box'\n",
    "t_type_lst = ['BOOSTING', 'MIL','KCF', 'TLD', 'MEDIANFLOW', 'GOTURN', 'CSRT', 'MOSSE']\n",
    "t_type_index = 0 # used to change tracker type\n",
    "t_type_text = t_type_lst[t_type_index]\n",
    "t_type_min, t_type_max = 0, len(t_type_lst)-1\n",
    "txt_font_size, txt_thickness = 2, 3\n",
    "\n",
    "k = 0 # used for key press\n",
    "k_timer = 1 # wait time for keyboard press\n",
    "frame_counter = 0 # used for resetting the frame\n",
    "\n",
    "cv2.namedWindow(win_name, cv2.WINDOW_AUTOSIZE)\n",
    "\n",
    "# Bounding box\n",
    "ball_detector_bbox = (-1, -1, -1, -1) # bounding box of Detector\n",
    "ball_tracker_bbox = (-1, -1, -1, -1) # bounding box of Tracker\n",
    "\n",
    "bbox_tracker_color = (255, 125, 0)\n",
    "bbox_detector_color = (125, 255, 0)\n",
    "FLAG_CHANGE_TRACKER = False\n",
    "FLAG_TRACKER_OK = False\n",
    "FLAG_DETECT_OK = False # Flag to use if ball was detected\n",
    "detection_timer = 10 # Detect every Nth frame\n",
    "thickness = 2\n",
    "FLAG_INIT = False\n",
    "downscale_size = 0.75\n",
    "tracker = None\n",
    "no_detect = 0\n",
    "\n",
    "'''\n",
    "--- TRACKER configurations\n",
    "'''\n",
    "\n",
    "'''\n",
    "+++ YOLO v3 detector variables\n",
    "'''\n",
    "# Initialize the parameters\n",
    "objectnessThreshold = 0.5 # Objectness threshold\n",
    "confThreshold = 0.5       # Confidence threshold\n",
    "nmsThreshold = 0.4        # Non-maximum suppression threshold\n",
    "inpWidth = 416            # Width of network's input image\n",
    "inpHeight = 416           # Height of network's input image\n",
    "\n",
    "y3_weights_path = './data/yolov3.weights'\n",
    "y3_config_path = './data/yolov3.cfg'\n",
    "coco_classes_path = './data/coco.names' # file with multiple classes\n",
    "ball_classes_path = './data/target.names' # only sports ball\n",
    "choice_path = coco_classes_path\n",
    "classes = None\n",
    "with open(choice_path, 'rt') as f:\n",
    "  classes = f.read().strip('\\n').split('\\n')\n",
    "\n",
    "# load the network\n",
    "net = cv2.dnn.readNetFromDarknet(y3_config_path, y3_weights_path)\n",
    "# net = cv2.dnn.DNN_TARGET_OPENCL(y3_config_path, y3_weights_path)\n",
    "\n",
    "'''\n",
    "--- YOLO v3 Configuration\n",
    "'''\n",
    "\n",
    "if not cap.isOpened():\n",
    "  print('Could not open the video')\n",
    "else:\n",
    "  cv2.createTrackbar('Trackers: ', win_name, t_type_min, t_type_max, EventTrkChangeTrackerType)\n",
    "  while cap.isOpened() and k != 27:\n",
    "\n",
    "    if k == ord('r'):\n",
    "      '''\n",
    "      When the 'r' keyboard button is pressed, reset the video\n",
    "      '''\n",
    "      # reset frame to position 0\n",
    "      frame_counter = 0\n",
    "      cap.set(cv2.CAP_PROP_POS_FRAMES, frame_counter)\n",
    "\n",
    "    # read the frame  \n",
    "    frameIsRead, f = cap.read()\n",
    "\n",
    "    if not frameIsRead:\n",
    "      print('Video read unsuccessful')\n",
    "      break\n",
    "\n",
    "    # keep track of frame tick\n",
    "    frame_counter += 1\n",
    "    # Attempt to down scale for FPS Boost\n",
    "    row, col, dim = f.shape\n",
    "    row, col = int(row*downscale_size), int(col*downscale_size)\n",
    "    dim = (col, row)\n",
    "    frame_downscale = cv2.resize(f, dim, interpolation = cv2.INTER_AREA)\n",
    "    if not FLAG_INIT:\n",
    "      ball_tracker_bbox = cv2.selectROI(ini_win_name, frame_downscale)\n",
    "      tracker = Set_Tracker(t_type_lst, t_type_index)\n",
    "      FLAG_INIT = tracker.init(frame_downscale, ball_tracker_bbox)\n",
    "      if FLAG_INIT:\n",
    "        print('Tracker Initialized')\n",
    "      else:\n",
    "        print('Tracker not initialized')\n",
    "      cv2.destroyWindow(ini_win_name)\n",
    "    \n",
    "    # perform detection every Nth frames\n",
    "    ball_detector_bbox = (-1, -1, -1, -1)\n",
    "    if (frame_counter - 1) % detection_timer == 0:\n",
    "      # ball_detector_bbox gets updated inside Detect_Object\n",
    "      detect_frame = Detect_Object(frame_downscale)\n",
    "      if not FLAG_DETECT_OK:\n",
    "        no_detect += 1\n",
    "      else:\n",
    "        no_detect = 0\n",
    "\n",
    "    # ball_tracker_bbox gets updated inside Track_Objects\n",
    "    track_frame = Track_Object(frame_downscale, tracker)\n",
    "\n",
    "    tracker, ball_tracker_bbox = ValidateTracker(ball_tracker_bbox, ball_detector_bbox, tracker, frame_downscale)\n",
    "    t0, t1, t2, t3 = ball_tracker_bbox\n",
    "    d0, d1, d2, d3 = ball_detector_bbox\n",
    "\n",
    "    print('Detector: ' + str(sum(ball_detector_bbox)))\n",
    "    print('Tracker: ' + str(sum(ball_tracker_bbox)))\n",
    "    print('\\n')\n",
    "    if sum(ball_detector_bbox) >= 0:\n",
    "      cv2.rectangle(frame_downscale, (int(d0), int(d1)), (int(d0+d2), int(d1+d3)), bbox_detector_color, thickness, cv2.LINE_AA)\n",
    "    if sum(ball_tracker_bbox) >= 0 and no_detect < 2:\n",
    "      cv2.rectangle(frame_downscale, (int(t0), int(t1)), (int(t0+t2), int(t1+t3)), bbox_tracker_color, thickness, cv2.LINE_AA)\n",
    "      cv2.putText(frame_downscale, 'Tracker: ' + str(tracker),(10,row), cv2.FONT_HERSHEY_PLAIN, txt_font_size, (255, 255, 255), txt_thickness, cv2.LINE_AA)\n",
    "    else:\n",
    "      cv2.putText(frame_downscale, 'No object tracked',(10,row), cv2.FONT_HERSHEY_PLAIN, txt_font_size, (255, 255, 255), txt_thickness, cv2.LINE_AA)\n",
    "    cv2.imshow(win_name, frame_downscale)\n",
    "    \n",
    "    # read keyboard input\n",
    "    k = cv2.waitKey(k_timer)\n",
    "\n",
    "# release of the cap object\n",
    "cap.release()\n",
    "# close all windows\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
